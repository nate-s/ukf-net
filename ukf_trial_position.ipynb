{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import attn_modules as attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1a04d5-7c63-469b-9ba3-20f95bd850ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class encoder_attn(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This will be the single class called in each training pass. Has to handle averything for a single transformer. \n",
    "        We have three transformers each taking a different slice of autoencoder latent space\n",
    "        \n",
    "        input:\n",
    "            depth: the depth of each transformer layer all with dimension D\n",
    "            head: the number of heads in each local+global pair\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        dim_encoder = 8 # Dimension at AttnBlock \n",
    "        d_encoder = 2\n",
    "        num_heads_encoder = 1\n",
    "        layer_depth_encoder = 2\n",
    "        self.max_sequence_length = 15 # how many time steps we will use the same key before restarting\n",
    "\n",
    "        dim_dynamics = 256\n",
    "        d_dynamics = 2\n",
    "        num_heads_dynamics = 1\n",
    "        layer_depth_dynamics = 2\n",
    "        self.key = 0\n",
    "        emb = torch.rand((23, 4, 8))\n",
    "        self.e = nn.Parameter(data = emb, requires_grad=True)\n",
    "        emb_q = torch.rand((23, 1, 8))\n",
    "        self.e_q = nn.Parameter(data = emb_q, requires_grad=True)\n",
    "\n",
    "        at_l = attn.AttnLocal\n",
    "        at_g = attn.AttnGlobal\n",
    "        at_dyn = attn.AttnDyn\n",
    "\n",
    "        self.lin_map = nn.Linear(64,256)\n",
    "        self.q_map = nn.Linear(64,256)\n",
    "        self.dynamic_map = nn.Linear(8,1)\n",
    "\n",
    "        self.encode = nn.ModuleList([attn.attention_local_global_layer(dim = dim_encoder, depth = d_encoder, heads = num_heads_encoder, AttnType = at_l)\n",
    "                                for i in range(layer_depth_encoder)\n",
    "                                ])\n",
    "\n",
    "        self.dynamics = nn.ModuleList([attn.attention_local_global_layer(dim = dim_dynamics, depth = d_dynamics, heads = num_heads_dynamics, AttnType = at_dyn)\n",
    "                                for i in range(layer_depth_dynamics)\n",
    "                                ])\n",
    "\n",
    "    def key_emb(self,x):\n",
    "        \"\"\"\n",
    "        The forward takes either an image or a flat vector of arbitrary size, patch embeds it\n",
    "        then runs it through the corresponding attention network, the norms+avgpools+flattens it again\n",
    "        \"\"\"\n",
    "        skip = x\n",
    "        x = x.permute(2,0,1)\n",
    "        x = torch.concat((x, self.e), dim = 0).permute(1,0,2)\n",
    "        for layer in self.encode:\n",
    "            x = layer(x, x)\n",
    "        \n",
    "        x = x.reshape(8,64,-1).flatten(-2,-1)\n",
    "\n",
    "        return x\n",
    "       \n",
    "    def dynamic_update(self, q, k, v):\n",
    "\n",
    "        q = torch.concat((q.permute(2,0,1), self.e_q), dim = 0).permute(2,1,0) #.flatten()\n",
    "        q = self.q_map(q).squeeze().unsqueeze(0)\n",
    "        kv = torch.concat((k.unsqueeze(0),v),dim=1)\n",
    "\n",
    "        for layer in self.dynamics:\n",
    "            q = layer(q,kv)\n",
    "        \n",
    "        x = self.dynamic_map(q.permute(0,2,1))\n",
    "            \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key input torch.Size([4, 8, 41]) , Dynamic update input torch.Size([1, 8, 41])\n",
      "Dynamic attn model output torch.Size([256])\n",
      "True True True True\n"
     ]
    }
   ],
   "source": [
    "DyAttn = encoder_attn()\n",
    "x = torch.ones((8, 128, 32))\n",
    "l = torch.ones((1024, 28, 28))\n",
    "\n",
    "sig = torch.zeros((1,1,512,256)).squeeze().unsqueeze(0).requires_grad_(True)\n",
    "v_state = torch.rand((4,1,9))\n",
    "v_state_current = torch.rand((1,1,9))\n",
    "red = torch.ones(4,8,32)\n",
    "lat = torch.ones(1,8,32)\n",
    "v_state = v_state.repeat(1,8,1)\n",
    "\n",
    "v_state_current = v_state_current.repeat(1,8,1)\n",
    "Q = torch.concat((lat, v_state_current), dim = 2).requires_grad_(True) # [1, 8, 41]: 8 windows from 1024, size 32 per window, + 9 states\n",
    "inp = torch.concat((red.squeeze(), v_state), dim = 2)\n",
    "print('Key input', inp.shape,', Dynamic update input', Q.shape)\n",
    "\n",
    "t = DyAttn.key_emb(inp.requires_grad_(True))\n",
    "p = DyAttn.dynamic_update(Q, t, sig, 0).squeeze()\n",
    "\n",
    "print('Dynamic attn model output',p.shape)\n",
    "print(inp.requires_grad, t.requires_grad, Q.requires_grad, sig.requires_grad)\n",
    "torch.mean(p).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqrtm\n",
    "class MatrixSquareRoot(Function):\n",
    "    \"\"\"Square root of a positive definite matrix.\n",
    "    NOTE: matrix square root is not differentiable for matrices with\n",
    "          zero eigenvalues.\n",
    "          from https://github.com/steveli/pytorch-sqrtm\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        m = input.detach().cpu().numpy().astype(np.float_)\n",
    "        sqrtm = torch.from_numpy(scipy.linalg.sqrtm(m).real).to(input)\n",
    "        ctx.save_for_backward(sqrtm)\n",
    "        return sqrtm\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            sqrtm, = ctx.saved_tensors\n",
    "            sqrtm = sqrtm.data.cpu().numpy().astype(np.float_)\n",
    "            gm = grad_output.data.cpu().numpy().astype(np.float_)\n",
    "\n",
    "            # Given a positive semi-definite matrix X,\n",
    "            # since X = X^{1/2}X^{1/2}, we can compute the gradient of the\n",
    "            # matrix square root dX^{1/2} by solving the Sylvester equation:\n",
    "            # dX = (d(X^{1/2})X^{1/2} + X^{1/2}(dX^{1/2}).\n",
    "            grad_sqrtm = scipy.linalg.solve_sylvester(sqrtm, sqrtm, gm)\n",
    "\n",
    "            grad_input = torch.from_numpy(grad_sqrtm).to(grad_output)\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "sqrtm = MatrixSquareRoot.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UKF\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import xnet, whack_nn, depth_net # placeholder for wriitng code\n",
    "\n",
    "\"\"\"\n",
    "TODO:\n",
    "1. integrate attn  net to kf\n",
    "2. Finish squeeze excite block\n",
    "\n",
    "DONE:\n",
    "1. encoder for the transformer\n",
    "2. decoder for the transformer\n",
    "3. just the whole transformer lol\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def RelU_1(x):\n",
    "    return torch.maximum(torch.maximum(x, -1), 1)\n",
    "\n",
    "\n",
    "# Returns: [2NxN] sigma points and P_k\n",
    "def sigma_points(x, P_u, Q_k):\n",
    "    \"\"\"\n",
    "    Inputs: [1xN] vector, the previous covaroiance matrix P_u[+|k-1], and process noise Q_k\n",
    "    Returns: [2NxN] vector of sigma points, and a [NxN] matrix of covariance P_u[-|k]\n",
    "    \"\"\"\n",
    "\n",
    "    sigma = x.repeat(1,1,1,x.shape[2])\n",
    "    print('Sigma points for',x.shape[2])\n",
    "\n",
    "    p = sqrtm(x.shape[2]*torch.abs(P_u.squeeze()))    \n",
    "    sigma_plus = sigma + p\n",
    "    sigma_minus = sigma - p\n",
    "\n",
    "    sigma = torch.concat((sigma_plus, sigma_minus), dim=3)\n",
    "    scale_factor = 1/(2*x.shape[2])\n",
    "    x_bar = torch.mean(sigma, dim=3)\n",
    "    sum = torch.zeros((x.shape[1],x.shape[2],x.shape[2]))\n",
    "    extra = np.zeros((x.shape[2]*2,x.shape[2],x.shape[2]))\n",
    "\n",
    "    for i2 in range(sigma.shape[1]):\n",
    "        for i1 in range(sigma.shape[3]):\n",
    "            vecp = sigma[0,0,:,i1].unsqueeze(1)\n",
    "            c = (vecp.squeeze()-x_bar[0,i2].squeeze().T)\n",
    "            sum[i2] += torch.matmul(c.unsqueeze(-1), c.unsqueeze(0))\n",
    "\n",
    "    P_k = sum*scale_factor + (Q_k**2)*0.01\n",
    "    \n",
    "    return P_k, sigma.permute(0,1,3,2) #, extra # The sigma points for X_hat[k|k-1] and the cross variance matrix for X_hat[k|k-1]\n",
    "    #return sigma, x_bar\n",
    "\n",
    "# Returns: Updated X post, P_k post, K_k for record keeping\n",
    "def UKF_update(x_sigma, y_sigma, R_k, P_u, Y):\n",
    "\n",
    "    \"\"\"\n",
    "    P_xx, p_hat, sigma_Y_p, state_Y, self.R_kp\n",
    "    Inputs: uhhhhhhh... the [2NxN] sigma points for X, the [2NxN] outputs Y from the equation H(X_sigma_i) = Y_sigma_i,\n",
    "    the measurment [1xN] noise R_k, the previous [NxN] covariance matrix P_u, and the actual [1xN] state estimate Y\n",
    "\n",
    "    Returns: updated vector X_posteriori, the updated covariance matrix P_k+, and Kalman gain K_k\n",
    "    p = sqrtm(x.shape[2]*torch.abs(P_u.squeeze()))    \n",
    "    sigma_plus = sigma + p\n",
    "    sigma_minus = sigma - p\n",
    "    \"\"\"\n",
    "    print('UKF for', x_sigma.shape[2])\n",
    "    \n",
    "    x_bar = torch.mean(x_sigma, dim=2) # This give a Nx1 vector of the means\n",
    "    y_bar = torch.mean(y_sigma, dim=2)\n",
    "    scale_factor = 1/(x_sigma.shape[2])\n",
    "\n",
    "    P_xy = torch.zeros((x_sigma.shape[1],x_bar.shape[2],x_bar.shape[2]))\n",
    "    P_yy = P_xy\n",
    "    \n",
    "    for i2 in range(P_xy.shape[0]):\n",
    "        for i1 in range(x_sigma.shape[3]):\n",
    "            vec_x = x_sigma[0,0,i1,:]#.unsqueeze(1)\n",
    "            vec_y = y_sigma[0,0,i1,:]#.unsqueeze(1)\n",
    "            \n",
    "            c_1 = (vec_x.squeeze()-x_bar[0,i2].squeeze().T)\n",
    "            c_2 = (vec_y.squeeze()-y_bar[0,i2].squeeze().T)\n",
    "\n",
    "            P_xy[i2] += torch.matmul(c_1.unsqueeze(-1), c_2.unsqueeze(0)) * scale_factor\n",
    "            P_yy[i2] += torch.matmul(c_2.unsqueeze(-1), c_2.unsqueeze(0)) * scale_factor # R_k is sigma so convert to sigma^2\n",
    "\n",
    "    P_yy = P_yy + (R_k**2)\n",
    "\n",
    "    K_k = torch.matmul(P_xy, torch.inverse(P_yy))\n",
    "    if (K_k.shape[0] > 1):\n",
    "        K_k = torch.mean(K_k, dim=0)\n",
    "   \n",
    "    res = (Y - y_bar).squeeze().T\n",
    "\n",
    "    X_k_posterior = x_bar.squeeze() + torch.matmul(K_k, res).unsqueeze(0).permute(0,2,1).squeeze()\n",
    "   \n",
    "    P_k_posterior = P_u - torch.matmul(K_k.squeeze(), torch.matmul(P_yy.squeeze(), K_k.squeeze().T)).unsqueeze(0)\n",
    "\n",
    "    return X_k_posterior, P_k_posterior, K_k # Returns X_k|k, P_k|k, K_k\n",
    "\n",
    "# Returns: X_hat\n",
    "class dynamic_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Module predicts the current states based on learned and physical dynamic models. Is run between frames\n",
    "        Inputs: Vehicle state time k-1, latent features time k-1, dt\n",
    "        Returns: Vehicle state prediciton X_k_hat and latent feature prediciton X_thetaHat_k at time k\n",
    "        \"\"\"\n",
    "        self.model = encoder_attn()# this will be the full transformer\n",
    "        self.dynamics_v = dynamic_model_vehicle()\n",
    "        self.sigma_ = sigma_points\n",
    "        \n",
    "       \n",
    "    def forward(self, state_vehicle, state_latent, key, dt, P_x, P_theta,  Q_l, Q_x):\n",
    "        #print('Vehicle', state_vehicle.shape, 'latent', state_latent.shape)\n",
    "        P_x, vehicle_sigma = self.sigma_(state_vehicle, P_x, Q_x) # Convert vehicle state into sigma points\n",
    "        x_p_hat_sigma = self.dynamics_v(vehicle_sigma, dt) # Model of vehicle dynamcis in real world with state space matrix. Input: [X_k-1_sigma, dt] Return: posteriori estimate X_k_hat\n",
    "        x_p_hat = torch.mean(x_p_hat_sigma, dim = 2) # Mean of sigma points represent \"true\" posterior state\n",
    "        \n",
    "        for i1 in range(state_latent.shape[0]):\n",
    "            s = state_latent[i1].unsqueeze(0)\n",
    "            P_theta_, latent_sigma = self.sigma_(s, P_theta, Q_l) # Convert latent space into sigma points and pass as \"Values\" through transformer\n",
    "\n",
    "        v_state_current = x_p_hat.repeat(1,8,1)\n",
    "        Q = torch.concat((state_latent.reshape((1,8,32)), v_state_current), dim = 2) # [1, 8, 41]: 8 windows from 1024, size 32 per window, + 9 states\n",
    "        K = key\n",
    "        V = latent_sigma.squeeze().unsqueeze(0)\n",
    "        x_theta = self.model.dynamic_update(Q, K, V).unsqueeze(0) #inputs: q, k, v #latent_sigma, , dt, P_theta, P_x\n",
    "\n",
    "        for i1 in range(state_latent.shape[0]):\n",
    "            s = x_theta[i1].unsqueeze(0)\n",
    "            P_theta_, x_theta_sigma = self.sigma_(s, P_theta, Q_l) # Convert latent space into sigma points and pass as \"Values\" through transformer\n",
    "        return x_theta_sigma, x_p_hat_sigma, P_x, P_theta_ # X_theta is the predicted theta state , X_phat is the predicted vehicle state Dr. arguelles, Dr. Day, Dr. Huanyu, \n",
    "\n",
    "    def embed(self, x_theta, x_vehicle):\n",
    "        # Inputs: latent space and vehicle state for last 4 time steps [k-1,k-4]\n",
    "        v_state = x_vehicle.repeat(1,8,1)\n",
    "        inp = torch.concat((x_theta.squeeze(), v_state), dim = 2)\n",
    "\n",
    "        k = self.model.key_emb(inp)\n",
    "        return k\n",
    "        \n",
    "\n",
    "class dynamic_model_vehicle(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Inputs: vehicle state X_k, dt\n",
    "        Returns: Vehicle estimated state X_k+dt\n",
    "        \"\"\"\n",
    "        x = np.zeros(3)\n",
    "        x_ = torch.from_numpy(x)\n",
    "        parameters = nn.Parameter(data = x_, requires_grad = True) # Define dynamic model as nn parameters to propagate gradients through\n",
    "\n",
    "    def forward(self, x, dt):\n",
    "        dynamics_k = x*dt\n",
    "\n",
    "        return dynamics_k\n",
    "\n",
    "\n",
    "class UKF(nn.Module):\n",
    "    def __init__(self, l_size, s_size, l_hist, v_hist):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dynamics = dynamic_model()\n",
    "        self.sigma_ = sigma_points\n",
    "        self.ukf = UKF_update\n",
    "\n",
    "        self.s_l = l_size # 1024 // (8*4)\n",
    "        self.s_v = torch.eye(s_size)\n",
    "\n",
    "        R_tensor_p = torch.eye(s_size) * torch.abs(torch.randn(s_size)) #self.s_v.shape) #torch.tensor(self.s_v, dtype=torch.double).random_(0,1) # Initialize measurement noise as random tensor [0,1]\n",
    "        R_tensor_l = torch.eye(l_size) * torch.abs(torch.randn(l_size)) # torch.tensor(torch.eye(49), dtype=torch.double).random_(0,1) # Initialize measurement noise as random tensor [0,1]\n",
    "        Q_tensor = torch.eye(s_size) * torch.abs(torch.randn(s_size)) # torch.tensor(6, dtype=torch.double).random_(0,1) # Initialize vehicle process noise as random tensor [0,1] for the 6dof\n",
    "        Q_tensor_l = torch.eye(l_size) * torch.abs(torch.randn(self.s_l)) # torch.tensor(self.s_l, dtype=torch.double).random_(0,1) # Initialize latent process noise as random tensor [0,1]\n",
    "\n",
    "        self.Q_k_x = nn.Parameter(data = Q_tensor, requires_grad = True) # Learned process noise parameters\n",
    "        self.Q_k_l = nn.Parameter(data =Q_tensor_l, requires_grad = True) # Learned process noise parameters\n",
    "        self.R_kp = nn.Parameter(data = R_tensor_p, requires_grad = True) # Learned measurement noise parameters\n",
    "        self.R_kl = nn.Parameter(data = R_tensor_l, requires_grad = True) # Learned measurement noise parameters\n",
    "\n",
    "        self.tf_len = 15\n",
    "        self.embed = True\n",
    "        self.key = 0\n",
    "\n",
    "        self.energy = 0\n",
    "        self.threshold = 10\n",
    "        self.latent_history = l_hist\n",
    "        self.vehicle_history = v_hist\n",
    "\n",
    "    def predictor(self, image_t2, latent, x_vehicle, dt, P_xx_prior, P_xxl_prior): # Inputs: image at time t+1, vehicle state at time t, altent time t/k\n",
    "\n",
    "         # either embed the new latents and states every tf_len steps/ based on some energy metric above a threshold\n",
    "        if 1: #self.energy > self.threshold: # All good jsut need to update state history each loop\n",
    "            self.key = self.dynamics.embed(self.latent_history, self.vehicle_history)\n",
    "\n",
    "        # Priori update---------------\n",
    "        p_hat, latent_hat, P_xx, P_xxl = self.F(latent, x_vehicle, P_xx_prior, P_xxl_prior, dt) # F(X:t-1|t-1) -> return state for t|t-1\n",
    "        p_hat_mean = torch.mean(p_hat, dim=2)\n",
    "        l_hat_mean = torch.mean(latent_hat, dim=2)\n",
    "\n",
    "        # Measurement Y prediction----------\n",
    "        sigma_Y_p, sigma_Y_l = self.H(p_hat_mean, l_hat_mean, P_xx, P_xxl) # Collect measurement prediction by passing the latent sigma points through odom net H(X)\n",
    "        # Collect measurments Y-----------\n",
    "\n",
    "        return p_hat, sigma_Y_p, P_xx, latent_hat, sigma_Y_l, P_xxl, l_hat_mean, p_hat_mean\n",
    "\n",
    "    def update(self, p_hat, sigma_Y_p, P_xx, state_Y, latent_hat, sigma_Y_l, P_xxl, latent_Y):\n",
    "        # Perform UKF update with X, Yhat, and Y\n",
    "        # x_sigma, y_sigma, R_k, P_u, Y\n",
    "        X_kpose_post, P_kp_post, K_kp = self.ukf(p_hat, sigma_Y_p, self.R_kp, P_xx, state_Y) # X_k is new latent vector and vehicle state, P_k is new P_k, K_k is just there for interesting plots lol | X_hat_prior, Y_hat, self.R_k, P_k_prior, Y\n",
    "\n",
    "        X_klatent_post, P_kl_post, K_kl = self.ukf(latent_hat, sigma_Y_l, self.R_kl, P_xxl.unsqueeze(0), latent_Y) # X_k is new latent vector and vehicle state, P_k is new P_k, K_k is just there for interesting plots lol | X_hat_prior, Y_hat, self.R_k, P_k_prior, Y\n",
    "      \n",
    "        return X_kpose_post, X_klatent_post, P_kp_post, P_kl_post, K_kp, K_kl\n",
    "\n",
    "\n",
    "    def F(self, latent, x_vehicle, P_xx_prior, P_xxl_prior, dt):\n",
    "        \"\"\"\n",
    "        Inputs: Latent features, 6dof Vehicle state , P_x from t-1, P_l from k-1, dt\n",
    "        Returns: 6dof vehicle time t, latent feature prediction time k, covar x, covar latent \n",
    "        \"\"\"\n",
    "        latent_hat, xhat_p, P_xhat, P_lhat = self.dynamics(x_vehicle, latent, self.key, dt, P_xx_prior, P_xxl_prior, self.Q_k_l, self.Q_k_x) # takes vehicle state time t, latent space k, current key, dt: returns vehicle state k+1, latent space k+1\n",
    "        return xhat_p, latent_hat, P_xhat, P_lhat # Pose estimated by latent space forecasting and odom net, Pose estimated by physical dynamics, latent space forecast\n",
    "\n",
    "\n",
    "    def H(self, p_hat, latent_hat, P_xx, P_xxl):\n",
    "        # Measurement model H(X_hat) = Y_hat\n",
    "        P_xx, sigma_p_prior = self.sigma_(p_hat.reshape(1,1,p_hat.shape[2],1), P_xx.squeeze(), self.Q_k_x) # Convert t|t-1 to sigma points\n",
    "        P_xxl, sigma_l_prior = self.sigma_(latent_hat.unsqueeze(-1), P_xxl, self.Q_k_l) # Convert k|k-1 to sigma points\n",
    "        \n",
    "        #yhat_pose_sigma = self.pose(sigma_l_prior) \n",
    "        yhat_pose_sigma = sigma_p_prior # self.pose(sigma_l_prior) # takes latent space sigma points at k+1: returns vehicle state sigma K+1\n",
    "        return yhat_pose_sigma, sigma_l_prior # Yhat at time t+1 based on sigma from latent hat\n",
    "\n",
    "\n",
    "class SE_mapped(nn.Module):\n",
    "    def __init__(self, inp, reduction_factor):\n",
    "        super().__init__()\n",
    "        i = inp // reduction_factor\n",
    "        self.rf = reduction_factor\n",
    "        self.c1 = nn.Conv2d(i, i, 3, 2, 1)\n",
    "        self.c2 = nn.Conv2d(i, i // 2, 3, 2, 1)\n",
    "        self.c3 = nn.Conv2d(i//2, i//4, 7)\n",
    "        self.bn = nn.BatchNorm2d(i)\n",
    "\n",
    "        self.map_mul = nn.Linear(256, 1024)\n",
    "        self.map_add = nn.Linear(256, 1024)\n",
    "\n",
    "        self.act = nn.PReLU()\n",
    "\n",
    "    def encode(self, inp): # Inp is latent space, im is image\n",
    "       \n",
    "        batch_size = 1 #inp.shape[0]\n",
    "        \n",
    "        inp_ = inp.reshape(batch_size, self.rf, -1, inp.shape[2], inp.shape[2]).squeeze()\n",
    "        x = self.c1(inp_)\n",
    "        x = self.c2(x)\n",
    "        x_encoded = self.c3(x).flatten().unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "        return x_encoded\n",
    "\n",
    "    def decode(self, x_, skip):\n",
    "        \"\"\"\n",
    "        Will take in a flat vector since this is all done with transformers. Its got to expand back into\n",
    "        two inp//reduction_factor vectors. One for adding one for multiplying\n",
    "        \"\"\"\n",
    "        x_mul = self.act(self.map_mul(x_))\n",
    "        x_add = self.act(self.map_add(x_))\n",
    "        print(x_mul.shape, skip.shape)\n",
    "        x = (skip.permute(0,2,3,1) * x_mul + x_add).reshape(8, 128, 28, 28) # skip connection gets perturbed by a mult and add method\n",
    "        print(x.shape)\n",
    "        x = self.bn(x)\n",
    "        return x_mul, x_add\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma points for 9\n",
      "Sigma points for 256\n",
      "Sigma points for 256\n",
      "Sigma points for 9\n",
      "Sigma points for 256\n",
      "UKF for 18\n",
      "UKF for 512\n",
      "torch.Size([1024]) torch.Size([1, 1024, 28, 28])\n",
      "torch.Size([8, 128, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "se = SE_mapped(1024,8)\n",
    "\n",
    "if 0:\n",
    "    latent = depth.latent(depth.encode(image_t1), 0) # Encode new image frame at time k,t to latent space\n",
    "latent = se.encode(latent_)\n",
    "\n",
    "# Perform everyhting up to measurement step\n",
    "p_hat, sigma_Y_p, P_xx, latent_hat, sigma_Y_l, P_xxl, l_hat_mean, p_hat_mean = ukf.predictor(image_t2, latent, x_vehicle, dt, P_xx_prior, P_xxl_prior)\n",
    "\n",
    "# Collect measurements\n",
    "if 0:\n",
    "    latent_Y = depth.latent(depth.encode(image_t2), 0) # Encode new image frame at time k,t to latent space\n",
    "    state_Y = pose(latent_Y)\n",
    "    \n",
    "latent_Y = l_hat_mean # Encode new image frame at time k,t to latent space\n",
    "state_Y = p_hat_mean\n",
    "\n",
    "# Perform ukf update step\n",
    "X_kpose_post, X_klatent_post, P_kp_post, P_kl_post, K_kp, K_kl = ukf.update(p_hat, sigma_Y_p, P_xx, state_Y, latent_hat, sigma_Y_l, P_xxl, latent_Y)\n",
    "out = se.decode(X_klatent_post, latent_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def placeholder():\n",
    "    x = 0\n",
    "\n",
    "\n",
    "l_history = torch.ones(4,8,32)\n",
    "v_history = torch.rand((4,1,9)) #.repeat(1,8,1)\n",
    "numVstates = 9\n",
    "numLfeatures = 256\n",
    "\n",
    "ukf = UKF(numLfeatures, numVstates, l_history, v_history)\n",
    "\n",
    "depth = placeholder()\n",
    "pose = odom_net()\n",
    "image_t1 = 0\n",
    "image_t2 = 0\n",
    "latent = torch.randn((1, 1, 256)).unsqueeze(-1)\n",
    "latent_ = torch.randn((1024,28,28)).unsqueeze(0)\n",
    "x_vehicle = torch.randn((9,1)).unsqueeze(0).unsqueeze(0)\n",
    "dt = 0\n",
    "P_xx_prior = torch.eye(9)*torch.abs(torch.rand(9)).unsqueeze(0)\n",
    "l_size = 256\n",
    "P_xxl_prior = torch.eye(l_size)*torch.abs(torch.rand(l_size)).unsqueeze(0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.8043, grad_fn=<MaxBackward1>) tensor(-5.0325e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.7070, grad_fn=<MaxBackward1>) tensor(-1.4109e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.6432, grad_fn=<MaxBackward1>) tensor(-1.5625e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.5914, grad_fn=<MaxBackward1>) tensor(-1.3885e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.5498, grad_fn=<MaxBackward1>) tensor(-1.8447e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.5264, grad_fn=<MaxBackward1>) tensor(-1.4063e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.5059, grad_fn=<MaxBackward1>) tensor(-1.6105e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4877, grad_fn=<MaxBackward1>) tensor(-1.3280e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4715, grad_fn=<MaxBackward1>) tensor(-1.5590e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4627, grad_fn=<MaxBackward1>) tensor(-1.3519e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4571, grad_fn=<MaxBackward1>) tensor(-1.5588e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4571, grad_fn=<MaxBackward1>) tensor(-1.2767e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4582, grad_fn=<MaxBackward1>) tensor(-1.4964e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4590, grad_fn=<MaxBackward1>) tensor(-1.8127e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4597, grad_fn=<MaxBackward1>) tensor(-1.5371e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4602, grad_fn=<MaxBackward1>) tensor(-1.7719e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4606, grad_fn=<MaxBackward1>) tensor(-1.5139e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4609, grad_fn=<MaxBackward1>) tensor(-1.5779e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4611, grad_fn=<MaxBackward1>) tensor(-1.5401e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4613, grad_fn=<MaxBackward1>) tensor(-1.3435e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4615, grad_fn=<MaxBackward1>) tensor(-1.5158e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4616, grad_fn=<MaxBackward1>) tensor(-1.3484e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4617, grad_fn=<MaxBackward1>) tensor(-1.5060e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4617, grad_fn=<MaxBackward1>) tensor(-1.3416e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4618, grad_fn=<MaxBackward1>) tensor(-1.4915e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4618, grad_fn=<MaxBackward1>) tensor(-1.3090e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4619, grad_fn=<MaxBackward1>) tensor(-1.5050e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4619, grad_fn=<MaxBackward1>) tensor(-1.2412e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4619, grad_fn=<MaxBackward1>) tensor(-1.4797e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4619, grad_fn=<MaxBackward1>) tensor(-1.3771e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4619, grad_fn=<MaxBackward1>) tensor(-1.5419e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4620, grad_fn=<MaxBackward1>) tensor(-1.3761e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4620, grad_fn=<MaxBackward1>) tensor(-1.5169e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4620, grad_fn=<MaxBackward1>) tensor(-1.5599e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4620, grad_fn=<MaxBackward1>) tensor(-1.5419e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4620, grad_fn=<MaxBackward1>) tensor(-1.2761e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n",
      "UKF for 512\n",
      "tensor(0.4620, grad_fn=<MaxBackward1>) tensor(-1.4919e-08, grad_fn=<MinBackward1>)\n",
      "Sigma points for 256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d6/9_0p0ctd5cd5q3f8lhpbzpc40000gn/T/ipykernel_63226/2564206340.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/d6/9_0p0ctd5cd5q3f8lhpbzpc40000gn/T/ipykernel_63226/2540199080.py\u001b[0m in \u001b[0;36msigma_points\u001b[0;34m(x, P_u, Q_k)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mvecp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvecp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0msum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mP_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale_factor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mQ_k\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# KalmanJob12\n",
    "\n",
    "if 1:\n",
    "    t = 256\n",
    "    Q_tensor = torch.abs(torch.eye(256) * torch.randn(256))\n",
    "    P_x = torch.abs(torch.eye(256)*torch.rand(256).unsqueeze(0))\n",
    "    x = torch.randn((1,1,256)).unsqueeze(-1)\n",
    "    y = torch.randn((256,1)).unsqueeze(0).unsqueeze(0)\n",
    "    Q_x = nn.Parameter(data = Q_tensor)\n",
    "    Q_tensor = torch.abs(torch.eye(256) * torch.randn(256))\n",
    "    R = nn.Parameter(data = Q_tensor)\n",
    "else:\n",
    "    t = 4\n",
    "    Q_tensor = torch.abs(torch.eye(t) * torch.randn(t))\n",
    "    P_x = torch.abs(torch.eye(t)*torch.rand(t).unsqueeze(0))\n",
    "    x = torch.randn((t,1)).unsqueeze(0).unsqueeze(0)\n",
    "    y = torch.randn((t,1)).unsqueeze(0).unsqueeze(0)\n",
    "    y = torch.randn((t,1)).unsqueeze(0).unsqueeze(0)\n",
    "    Q_x = nn.Parameter(data = Q_tensor)\n",
    "\n",
    "    m = np.array([0,0,1,1])\n",
    "    m_ = torch.from_numpy(m)\n",
    "\n",
    "    R = nn.Parameter(data = Q_tensor)\n",
    "\n",
    "\n",
    "\n",
    "if 0:\n",
    "    a, b = sigma_points(x, P_x, Q_x)\n",
    "    print(a,b)\n",
    "\n",
    "\n",
    "if 0:\n",
    "    for i1 in range(50):\n",
    "        p, x = sigma_points(x, P_x, Q_x)\n",
    "        x = x.unsqueeze(-1)\n",
    "        x_ = torch.mean(x, dim=2)\n",
    "        x, P_x, K_k = UKF_update(x, x, R, p, y)\n",
    "        \n",
    "        print(P_x.max(), P_x.min())\n",
    "        x = x.reshape(1,1,t,1)\n",
    "        P_x = P_x.squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(a.shape, b.shape)\n",
    "x_bar = b\n",
    "i2 = 0\n",
    "vecp = a[0,0,:,i1].unsqueeze(1)\n",
    "print(vecp.squeeze().shape,x_bar[0,i2].shape)\n",
    "c = (vecp.squeeze()-x_bar[0,i2].squeeze().T)\n",
    "print(c)\n",
    "print(torch.matmul(c.unsqueeze(-1), c.unsqueeze(0)).detach().numpy())\n",
    "\n",
    "#torch.matmul((vecp.squeeze()-x_bar[0,i2].squeeze().T), (vecp.squeeze()-x_bar[0,i2].squeeze().T).T)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "image_t2 = 0\n",
    "latent = torch.randn((1, 1, 256)).unsqueeze(-1)\n",
    "latent_ = torch.randn((1024,28,28)).unsqueeze(0)\n",
    "x_vehicle = torch.randn((6,1)).unsqueeze(0).unsqueeze(0)\n",
    "dt = 0\n",
    "P_xx_prior = torch.eye(6)*torch.abs(torch.rand(6)).unsqueeze(0)\n",
    "l_size = 256\n",
    "P_xxl_prior = torch.eye(l_size)*torch.abs(torch.rand(l_size)).unsqueeze(0)\n",
    "\n",
    "\n",
    "#se = SE_mapped(1024, 8)\n",
    "ukf = UKF(l_size)\n",
    "\n",
    "#o = se.encode(latent_).flatten()\n",
    "#print(o.shape)\n",
    "\n",
    "X_p, X_l, P_xx_post, P_xxl_post, K_kp, K_kl = ukf.forward(image_t2, latent, x_vehicle, dt, P_xx_prior, P_xxl_prior)\n",
    "\n",
    "#print('post')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c23caf59b7a145a3d8a2045a295f4c2fdde335662298f46d08c971156aa4749"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
